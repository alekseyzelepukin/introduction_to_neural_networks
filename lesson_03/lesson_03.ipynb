{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Практическое задание\n",
    "\n",
    "<ol>\n",
    "    <li>Попробуйте обучить нейронную сеть на TensorFlow 2 на любом датасете imdb_reviews. \n",
    "        Опишите в комментарии к уроку - какой результата вы добились от нейросети? Что помогло вам улучшить ее точность?<br><br>\n",
    "    </li>\n",
    "    <li>*Поработайте с документацией TensorFlow 2. Найдите полезные команды не разобранные на уроке.</li>\n",
    "    \n",
    "    \n",
    "</ol>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.2.0\n"
     ]
    }
   ],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "\n",
    "# TensorFlow and tf.keras\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "# Helper libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# зафиксируем счетчик псевдослучайных чисел\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import imdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# загрузим данные imdb\n",
    "\n",
    "NUM_WORDS = 30000\n",
    "\n",
    "(train_data, train_labels), (test_data, test_labels) = imdb.load_data(num_words=NUM_WORDS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training entries: 25000, labels: 25000\n"
     ]
    }
   ],
   "source": [
    "print(\"Training entries: {}, labels: {}\".format(len(train_data), len(train_labels)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 14, 22, 16, 43, 530, 973, 1622, 1385, 65, 458, 4468, 66, 3941, 4, 173, 36, 256, 5, 25, 100, 43, 838, 112, 50, 670, 22665, 9, 35, 480, 284, 5, 150, 4, 172, 112, 167, 21631, 336, 385, 39, 4, 172, 4536, 1111, 17, 546, 38, 13, 447, 4, 192, 50, 16, 6, 147, 2025, 19, 14, 22, 4, 1920, 4613, 469, 4, 22, 71, 87, 12, 16, 43, 530, 38, 76, 15, 13, 1247, 4, 22, 17, 515, 17, 12, 16, 626, 18, 19193, 5, 62, 386, 12, 8, 316, 8, 106, 5, 4, 2223, 5244, 16, 480, 66, 3785, 33, 4, 130, 12, 16, 38, 619, 5, 25, 124, 51, 36, 135, 48, 25, 1415, 33, 6, 22, 12, 215, 28, 77, 52, 5, 14, 407, 16, 82, 10311, 8, 4, 107, 117, 5952, 15, 256, 4, 2, 7, 3766, 5, 723, 36, 71, 43, 530, 476, 26, 400, 317, 46, 7, 4, 12118, 1029, 13, 104, 88, 4, 381, 15, 297, 98, 32, 2071, 56, 26, 141, 6, 194, 7486, 18, 4, 226, 22, 21, 134, 476, 26, 480, 5, 144, 30, 5535, 18, 51, 36, 28, 224, 92, 25, 104, 4, 226, 65, 16, 38, 1334, 88, 12, 16, 283, 5, 16, 4472, 113, 103, 32, 15, 16, 5345, 19, 178, 32]\n"
     ]
    }
   ],
   "source": [
    "print(train_data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# загрузим словарь\n",
    "\n",
    "word_index = imdb.get_word_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('fawn', 34701),\n",
       " ('tsukino', 52006),\n",
       " ('nunnery', 52007),\n",
       " ('sonja', 16816),\n",
       " ('vani', 63951),\n",
       " ('woods', 1408),\n",
       " ('spiders', 16115),\n",
       " ('hanging', 2345),\n",
       " ('woody', 2289),\n",
       " ('trawling', 52008)]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(word_index.items())[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# поменяем ключ-значение в словаре местами\n",
    "\n",
    "reverse_word_index = dict([(value, key) for (key, value) in word_index.items()])\n",
    "\n",
    "def decode_review(text):\n",
    "    return ' '.join([reverse_word_index.get(i, '?') for i in text])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"the as you with out themselves powerful lets loves their becomes reaching had journalist of lot from anyone to have after out atmosphere never more room titillate it so heart shows to years of every never going villaronga help moments or of every chest visual movie except her was several of enough more with is now current film as you of mine potentially unfortunately of you than him that with out themselves her get for was camp of you movie sometimes movie that with scary but pratfalls to story wonderful that in seeing in character to of 70s musicians with heart had shadows they of here that with her serious to have does when from why what have critics they is you that isn't one will very to as itself with other tricky in of seen over landed for anyone of and br show's to whether from than out themselves history he name half some br of 'n odd was two most of mean for 1 any an boat she he should is thought frog but of script you not while history he heart to real at barrel but when from one bit then have two of script their with her nobody most that with wasn't to with armed acting watch an for with heartfelt film want an\""
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decode_review(train_data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# обработаем тренировочные и тестовые данные для подачи в нейросеть\n",
    "\n",
    "maxlen = 256\n",
    "\n",
    "train_data = keras.preprocessing.sequence.pad_sequences(train_data, maxlen=maxlen)\n",
    "test_data = keras.preprocessing.sequence.pad_sequences(test_data, maxlen=maxlen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(256, 256)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_data[0]), len(train_data[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, None, 16)          480000    \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d (Gl (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 16)                272       \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 480,289\n",
      "Trainable params: 480,289\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# создадим нейросеть\n",
    "\n",
    "model = keras.Sequential()\n",
    "model.add(keras.layers.Embedding(NUM_WORDS, 16))\n",
    "model.add(keras.layers.GlobalAveragePooling1D())\n",
    "model.add(keras.layers.Dense(16, activation=tf.nn.relu))\n",
    "model.add(keras.layers.Dense(1, activation=tf.nn.sigmoid))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.6833 - accuracy: 0.6917\n",
      "Epoch 2/20\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.6134 - accuracy: 0.7967\n",
      "Epoch 3/20\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.4855 - accuracy: 0.8451\n",
      "Epoch 4/20\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.3739 - accuracy: 0.8788\n",
      "Epoch 5/20\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.3038 - accuracy: 0.8990\n",
      "Epoch 6/20\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.2577 - accuracy: 0.9116\n",
      "Epoch 7/20\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.2249 - accuracy: 0.9234\n",
      "Epoch 8/20\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.1985 - accuracy: 0.9338\n",
      "Epoch 9/20\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.1777 - accuracy: 0.9415\n",
      "Epoch 10/20\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.1584 - accuracy: 0.9496\n",
      "Epoch 11/20\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.1423 - accuracy: 0.9555\n",
      "Epoch 12/20\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.1284 - accuracy: 0.9612\n",
      "Epoch 13/20\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.1158 - accuracy: 0.9664\n",
      "Epoch 14/20\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.1043 - accuracy: 0.9708\n",
      "Epoch 15/20\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.0948 - accuracy: 0.9742\n",
      "Epoch 16/20\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.0853 - accuracy: 0.9780\n",
      "Epoch 17/20\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.0773 - accuracy: 0.9807\n",
      "Epoch 18/20\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.0702 - accuracy: 0.9830\n",
      "Epoch 19/20\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.0633 - accuracy: 0.9853\n",
      "Epoch 20/20\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.0575 - accuracy: 0.9871\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fbad12c4590>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# обучение нейросети\n",
    "\n",
    "model.fit(train_data,\n",
    "          train_labels,\n",
    "          epochs=20,\n",
    "          batch_size=256,\n",
    "          verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 [==============================] - 1s 666us/step - loss: 0.3461 - accuracy: 0.8760\n",
      "[0.34608596563339233, 0.876039981842041]\n"
     ]
    }
   ],
   "source": [
    "# результаты на тестовом наборе\n",
    "\n",
    "results = model.evaluate(test_data, test_labels)\n",
    "\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# улучшить точность нейросети помогло уменьшение нейронов в входном слое до 16\n",
    "# также на качество нейросети влияют: кол-во эпох и batch_size\n",
    "# на тестовом наборе данных удалось достичь качества accuracy = 0.876"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
