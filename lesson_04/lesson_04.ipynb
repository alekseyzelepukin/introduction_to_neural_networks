{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Практическое задание\n",
    "\n",
    "<ol>\n",
    "    <li>Попробовать улучшить точность распознования образов cifar 10 сверточной нейронной сетью, рассмотренной на уроке. Приложить анализ с описанием того, что улучшает работу нейронной сети и что ухудшает.\n",
    "    </li>\n",
    "    <li>Описать также в анализе какие необоходимо внести изменения  в получившуюся у вас нейронную сеть если бы ей нужно было работать не с cifar10, а с MNIST, CIFAR100 и IMAGENET.\n",
    "    </li>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# зафиксируем генератор псевдо случайных чисел\n",
    "\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CIFAR10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (50000, 32, 32, 3)\n",
      "50000 тренировочные примеры\n",
      "10000 тестовые примеры\n",
      "Использование data augmentation в реальном времени\n",
      "Epoch 1/1\n",
      "1563/1563 [==============================] - 110s 71ms/step - loss: 1.8736 - accuracy: 0.3091 - val_loss: 1.5602 - val_accuracy: 0.4299\n",
      "сохранить обученную модель как /Users/user/AnacondaProjects/introduction_to_neural_networks/lesson_04/saved_models/keras_cifar10_trained_model.h5 \n",
      "10000/10000 [==============================] - 4s 448us/step\n",
      "Test loss: 1.5601814893722534\n",
      "Test accuracy: 0.42989999055862427\n"
     ]
    }
   ],
   "source": [
    "# модель из урока\n",
    "\n",
    "from __future__ import print_function\n",
    "import keras # расскоментируйте эту строку, чтобы начать обучение\n",
    "from keras.datasets import cifar10\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "import os\n",
    "\n",
    "# установка параметров нейросети\n",
    "batch_size = 32\n",
    "num_classes = 10\n",
    "epochs = 1\n",
    "data_augmentation = True\n",
    "num_predictions = 20\n",
    "save_dir = os.path.join(os.getcwd(), 'saved_models')\n",
    "model_name = 'keras_cifar10_trained_model.h5'\n",
    "\n",
    "# разделение тренировочной и тестовой выборки\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "print('x_train shape:', x_train.shape)\n",
    "print(x_train.shape[0], 'тренировочные примеры')\n",
    "print(x_test.shape[0], 'тестовые примеры')\n",
    "\n",
    "# преобразование матрицы чисел 0-9 в бинарную матрицу чисел 0-1\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "\n",
    "# конфигурирование слоев нейросети\n",
    "model = Sequential()\n",
    "\n",
    "# слои нейросети отвественные за свертку и max-pooling\n",
    "model.add(Conv2D(32, (3, 3), padding='same',\n",
    "                 input_shape=x_train.shape[1:]))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(32, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3), padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(64, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "# полносвязные слои нейронной сети\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(num_classes))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "# инициализация RMSprop optimizer\n",
    "opt = keras.optimizers.RMSprop(lr=0.0001, decay=1e-6)\n",
    "\n",
    "# компиляция модели\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=opt,\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "\n",
    "if not data_augmentation:\n",
    "    print('Не используется data augmentation')\n",
    "    model.fit(x_train, y_train,\n",
    "              batch_size=batch_size,\n",
    "              epochs=epochs,\n",
    "              validation_data=(x_test, y_test),\n",
    "              shuffle=True)\n",
    "else:\n",
    "    print('Использование data augmentation в реальном времени')\n",
    "    # Препроцессинг и data augmentation в реальном времени:\n",
    "    datagen = ImageDataGenerator(\n",
    "        featurewise_center=False,\n",
    "        samplewise_center=False,\n",
    "        featurewise_std_normalization=False,\n",
    "        samplewise_std_normalization=False,\n",
    "        zca_whitening=False, \n",
    "        zca_epsilon=1e-06, \n",
    "        rotation_range=0, \n",
    "        width_shift_range=0.1,\n",
    "        height_shift_range=0.1,\n",
    "        shear_range=0., \n",
    "        zoom_range=0., \n",
    "        channel_shift_range=0.,\n",
    "        fill_mode='nearest',\n",
    "        cval=0.,\n",
    "        horizontal_flip=True,\n",
    "        vertical_flip=False,\n",
    "        rescale=None,\n",
    "        preprocessing_function=None,\n",
    "        data_format=None,\n",
    "        validation_split=0.0)\n",
    "\n",
    "    # запуск data augmentation через fit\n",
    "    #datagen.fit(x_train)\n",
    "\n",
    "    # запуск data augmentation через fit_generator\n",
    "    model.fit_generator(datagen.flow(x_train, y_train,\n",
    "                                     batch_size=batch_size),\n",
    "                        epochs=epochs,\n",
    "                        validation_data=(x_test, y_test),\n",
    "                        workers=4)\n",
    "\n",
    "# сохранение модели и весов\n",
    "if not os.path.isdir(save_dir):\n",
    "    os.makedirs(save_dir)\n",
    "model_path = os.path.join(save_dir, model_name)\n",
    "model.save(model_path)\n",
    "print('сохранить обученную модель как %s ' % model_path)\n",
    "\n",
    "# проверка работы обученной модели\n",
    "scores = model.evaluate(x_test, y_test, verbose=1)\n",
    "print('Test loss:', scores[0])\n",
    "print('Test accuracy:', scores[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (50000, 32, 32, 3)\n",
      "50000 тренировочные примеры\n",
      "10000 тестовые примеры\n",
      "Использование data augmentation в реальном времени\n",
      "Epoch 1/5\n",
      "1563/1563 [==============================] - 108s 69ms/step - loss: 1.8609 - accuracy: 0.3156 - val_loss: 1.5834 - val_accuracy: 0.4142\n",
      "Epoch 2/5\n",
      "1563/1563 [==============================] - 111s 71ms/step - loss: 1.5928 - accuracy: 0.4166 - val_loss: 1.4161 - val_accuracy: 0.4895\n",
      "Epoch 3/5\n",
      "1563/1563 [==============================] - 108s 69ms/step - loss: 1.4693 - accuracy: 0.4652 - val_loss: 1.2767 - val_accuracy: 0.5432\n",
      "Epoch 4/5\n",
      "1563/1563 [==============================] - 110s 70ms/step - loss: 1.3757 - accuracy: 0.5060 - val_loss: 1.2270 - val_accuracy: 0.5663\n",
      "Epoch 5/5\n",
      "1563/1563 [==============================] - 108s 69ms/step - loss: 1.3067 - accuracy: 0.5341 - val_loss: 1.2261 - val_accuracy: 0.5700\n",
      "сохранить обученную модель как /Users/user/AnacondaProjects/introduction_to_neural_networks/lesson_04/saved_models/keras_cifar10_trained_model_mod.h5 \n",
      "10000/10000 [==============================] - 4s 361us/step\n",
      "Test loss: 1.2261001792907715\n",
      "Test accuracy: 0.5699999928474426\n"
     ]
    }
   ],
   "source": [
    "# попробуем изменить количество эпох\n",
    "\n",
    "# установка параметров нейросети\n",
    "batch_size = 32\n",
    "num_classes = 10\n",
    "epochs = 5\n",
    "data_augmentation = True\n",
    "num_predictions = 20\n",
    "save_dir = os.path.join(os.getcwd(), 'saved_models')\n",
    "model_name = 'keras_cifar10_trained_model_mod.h5'\n",
    "\n",
    "# разделение тренировочной и тестовой выборки\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "print('x_train shape:', x_train.shape)\n",
    "print(x_train.shape[0], 'тренировочные примеры')\n",
    "print(x_test.shape[0], 'тестовые примеры')\n",
    "\n",
    "# преобразование матрицы чисел 0-9 в бинарную матрицу чисел 0-1\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "\n",
    "# конфигурирование слоев нейросети\n",
    "model = Sequential()\n",
    "\n",
    "# слои нейросети отвественные за свертку и max-pooling\n",
    "model.add(Conv2D(32, (3, 3), padding='same',\n",
    "                 input_shape=x_train.shape[1:]))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(32, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3), padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(64, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "# полносвязные слои нейронной сети\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(num_classes))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "# инициализация RMSprop optimizer\n",
    "opt = keras.optimizers.RMSprop(lr=0.0001, decay=1e-6)\n",
    "\n",
    "# компиляция модели\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=opt,\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "\n",
    "if not data_augmentation:\n",
    "    print('Не используется data augmentation')\n",
    "    model.fit(x_train, y_train,\n",
    "              batch_size=batch_size,\n",
    "              epochs=epochs,\n",
    "              validation_data=(x_test, y_test),\n",
    "              shuffle=True)\n",
    "else:\n",
    "    print('Использование data augmentation в реальном времени')\n",
    "    # Препроцессинг и data augmentation в реальном времени:\n",
    "    datagen = ImageDataGenerator(\n",
    "        featurewise_center=False,\n",
    "        samplewise_center=False,\n",
    "        featurewise_std_normalization=False,\n",
    "        samplewise_std_normalization=False,\n",
    "        zca_whitening=False, \n",
    "        zca_epsilon=1e-06, \n",
    "        rotation_range=0, \n",
    "        width_shift_range=0.1,\n",
    "        height_shift_range=0.1,\n",
    "        shear_range=0., \n",
    "        zoom_range=0., \n",
    "        channel_shift_range=0.,\n",
    "        fill_mode='nearest',\n",
    "        cval=0.,\n",
    "        horizontal_flip=True,\n",
    "        vertical_flip=False,\n",
    "        rescale=None,\n",
    "        preprocessing_function=None,\n",
    "        data_format=None,\n",
    "        validation_split=0.0)\n",
    "\n",
    "    # запуск data augmentation через fit\n",
    "    #datagen.fit(x_train)\n",
    "\n",
    "    # запуск data augmentation через fit_generator\n",
    "    model.fit_generator(datagen.flow(x_train, y_train,\n",
    "                                     batch_size=batch_size),\n",
    "                        epochs=epochs,\n",
    "                        validation_data=(x_test, y_test),\n",
    "                        workers=4)\n",
    "\n",
    "# сохранение модели и весов\n",
    "if not os.path.isdir(save_dir):\n",
    "    os.makedirs(save_dir)\n",
    "model_path = os.path.join(save_dir, model_name)\n",
    "model.save(model_path)\n",
    "print('сохранить обученную модель как %s ' % model_path)\n",
    "\n",
    "# проверка работы обученной модели\n",
    "scores = model.evaluate(x_test, y_test, verbose=1)\n",
    "print('Test loss:', scores[0])\n",
    "print('Test accuracy:', scores[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (50000, 32, 32, 3)\n",
      "50000 тренировочные примеры\n",
      "10000 тестовые примеры\n",
      "Использование data augmentation в реальном времени\n",
      "Epoch 1/1\n",
      "196/196 [==============================] - 54s 275ms/step - loss: 2.0880 - accuracy: 0.2226 - val_loss: 1.9110 - val_accuracy: 0.3251\n",
      "сохранить обученную модель как /Users/user/AnacondaProjects/introduction_to_neural_networks/lesson_04/saved_models/keras_cifar10_trained_model_mod.h5 \n",
      "10000/10000 [==============================] - 3s 337us/step\n",
      "Test loss: 1.911023249435425\n",
      "Test accuracy: 0.32510000467300415\n"
     ]
    }
   ],
   "source": [
    "# попробуем изменить batch_size\n",
    "\n",
    "# установка параметров нейросети\n",
    "batch_size = 256\n",
    "num_classes = 10\n",
    "epochs = 1\n",
    "data_augmentation = True\n",
    "num_predictions = 20\n",
    "save_dir = os.path.join(os.getcwd(), 'saved_models')\n",
    "model_name = 'keras_cifar10_trained_model_mod.h5'\n",
    "\n",
    "# разделение тренировочной и тестовой выборки\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "print('x_train shape:', x_train.shape)\n",
    "print(x_train.shape[0], 'тренировочные примеры')\n",
    "print(x_test.shape[0], 'тестовые примеры')\n",
    "\n",
    "# преобразование матрицы чисел 0-9 в бинарную матрицу чисел 0-1\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "\n",
    "# конфигурирование слоев нейросети\n",
    "model = Sequential()\n",
    "\n",
    "# слои нейросети отвественные за свертку и max-pooling\n",
    "model.add(Conv2D(32, (3, 3), padding='same',\n",
    "                 input_shape=x_train.shape[1:]))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(32, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3), padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(64, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "# полносвязные слои нейронной сети\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(num_classes))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "# инициализация RMSprop optimizer\n",
    "opt = keras.optimizers.RMSprop(lr=0.0001, decay=1e-6)\n",
    "\n",
    "# компиляция модели\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=opt,\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "\n",
    "if not data_augmentation:\n",
    "    print('Не используется data augmentation')\n",
    "    model.fit(x_train, y_train,\n",
    "              batch_size=batch_size,\n",
    "              epochs=epochs,\n",
    "              validation_data=(x_test, y_test),\n",
    "              shuffle=True)\n",
    "else:\n",
    "    print('Использование data augmentation в реальном времени')\n",
    "    # Препроцессинг и data augmentation в реальном времени:\n",
    "    datagen = ImageDataGenerator(\n",
    "        featurewise_center=False,\n",
    "        samplewise_center=False,\n",
    "        featurewise_std_normalization=False,\n",
    "        samplewise_std_normalization=False,\n",
    "        zca_whitening=False, \n",
    "        zca_epsilon=1e-06, \n",
    "        rotation_range=0, \n",
    "        width_shift_range=0.1,\n",
    "        height_shift_range=0.1,\n",
    "        shear_range=0., \n",
    "        zoom_range=0., \n",
    "        channel_shift_range=0.,\n",
    "        fill_mode='nearest',\n",
    "        cval=0.,\n",
    "        horizontal_flip=True,\n",
    "        vertical_flip=False,\n",
    "        rescale=None,\n",
    "        preprocessing_function=None,\n",
    "        data_format=None,\n",
    "        validation_split=0.0)\n",
    "\n",
    "    # запуск data augmentation через fit\n",
    "    #datagen.fit(x_train)\n",
    "\n",
    "    # запуск data augmentation через fit_generator\n",
    "    model.fit_generator(datagen.flow(x_train, y_train,\n",
    "                                     batch_size=batch_size),\n",
    "                        epochs=epochs,\n",
    "                        validation_data=(x_test, y_test),\n",
    "                        workers=4)\n",
    "\n",
    "# сохранение модели и весов\n",
    "if not os.path.isdir(save_dir):\n",
    "    os.makedirs(save_dir)\n",
    "model_path = os.path.join(save_dir, model_name)\n",
    "model.save(model_path)\n",
    "print('сохранить обученную модель как %s ' % model_path)\n",
    "\n",
    "# проверка работы обученной модели\n",
    "scores = model.evaluate(x_test, y_test, verbose=1)\n",
    "print('Test loss:', scores[0])\n",
    "print('Test accuracy:', scores[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (50000, 32, 32, 3)\n",
      "50000 тренировочные примеры\n",
      "10000 тестовые примеры\n",
      "Не используется data augmentation\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "50000/50000 [==============================] - 102s 2ms/step - loss: 1.7999 - accuracy: 0.3430 - val_loss: 1.5137 - val_accuracy: 0.4648\n",
      "сохранить обученную модель как /Users/user/AnacondaProjects/introduction_to_neural_networks/lesson_04/saved_models/keras_cifar10_trained_model_mod.h5 \n",
      "10000/10000 [==============================] - 3s 339us/step\n",
      "Test loss: 1.5136770641326904\n",
      "Test accuracy: 0.46480000019073486\n"
     ]
    }
   ],
   "source": [
    "# отключим data_augmentation\n",
    "\n",
    "# установка параметров нейросети\n",
    "batch_size = 32\n",
    "num_classes = 10\n",
    "epochs = 1\n",
    "data_augmentation = False\n",
    "num_predictions = 20\n",
    "save_dir = os.path.join(os.getcwd(), 'saved_models')\n",
    "model_name = 'keras_cifar10_trained_model_mod.h5'\n",
    "\n",
    "# разделение тренировочной и тестовой выборки\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "print('x_train shape:', x_train.shape)\n",
    "print(x_train.shape[0], 'тренировочные примеры')\n",
    "print(x_test.shape[0], 'тестовые примеры')\n",
    "\n",
    "# преобразование матрицы чисел 0-9 в бинарную матрицу чисел 0-1\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "\n",
    "# конфигурирование слоев нейросети\n",
    "model = Sequential()\n",
    "\n",
    "# слои нейросети отвественные за свертку и max-pooling\n",
    "model.add(Conv2D(32, (3, 3), padding='same',\n",
    "                 input_shape=x_train.shape[1:]))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(32, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3), padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(64, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "# полносвязные слои нейронной сети\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(num_classes))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "# инициализация RMSprop optimizer\n",
    "opt = keras.optimizers.RMSprop(lr=0.0001, decay=1e-6)\n",
    "\n",
    "# компиляция модели\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=opt,\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "\n",
    "if not data_augmentation:\n",
    "    print('Не используется data augmentation')\n",
    "    model.fit(x_train, y_train,\n",
    "              batch_size=batch_size,\n",
    "              epochs=epochs,\n",
    "              validation_data=(x_test, y_test),\n",
    "              shuffle=True)\n",
    "else:\n",
    "    print('Использование data augmentation в реальном времени')\n",
    "    # Препроцессинг и data augmentation в реальном времени:\n",
    "    datagen = ImageDataGenerator(\n",
    "        featurewise_center=False,\n",
    "        samplewise_center=False,\n",
    "        featurewise_std_normalization=False,\n",
    "        samplewise_std_normalization=False,\n",
    "        zca_whitening=False, \n",
    "        zca_epsilon=1e-06, \n",
    "        rotation_range=0, \n",
    "        width_shift_range=0.1,\n",
    "        height_shift_range=0.1,\n",
    "        shear_range=0., \n",
    "        zoom_range=0., \n",
    "        channel_shift_range=0.,\n",
    "        fill_mode='nearest',\n",
    "        cval=0.,\n",
    "        horizontal_flip=True,\n",
    "        vertical_flip=False,\n",
    "        rescale=None,\n",
    "        preprocessing_function=None,\n",
    "        data_format=None,\n",
    "        validation_split=0.0)\n",
    "\n",
    "    # запуск data augmentation через fit\n",
    "    #datagen.fit(x_train)\n",
    "\n",
    "    # запуск data augmentation через fit_generator\n",
    "    model.fit_generator(datagen.flow(x_train, y_train,\n",
    "                                     batch_size=batch_size),\n",
    "                        epochs=epochs,\n",
    "                        validation_data=(x_test, y_test),\n",
    "                        workers=4)\n",
    "\n",
    "# сохранение модели и весов\n",
    "if not os.path.isdir(save_dir):\n",
    "    os.makedirs(save_dir)\n",
    "model_path = os.path.join(save_dir, model_name)\n",
    "model.save(model_path)\n",
    "print('сохранить обученную модель как %s ' % model_path)\n",
    "\n",
    "# проверка работы обученной модели\n",
    "scores = model.evaluate(x_test, y_test, verbose=1)\n",
    "print('Test loss:', scores[0])\n",
    "print('Test accuracy:', scores[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (50000, 32, 32, 3)\n",
      "50000 тренировочные примеры\n",
      "10000 тестовые примеры\n",
      "Использование data augmentation в реальном времени\n",
      "Epoch 1/1\n",
      "1563/1563 [==============================] - 107s 68ms/step - loss: 1.9559 - accuracy: 0.2709 - val_loss: 1.6777 - val_accuracy: 0.3841\n",
      "сохранить обученную модель как /Users/user/AnacondaProjects/introduction_to_neural_networks/lesson_04/saved_models/keras_cifar10_trained_model_mod.h5 \n",
      "10000/10000 [==============================] - 4s 351us/step\n",
      "Test loss: 1.6776920598983764\n",
      "Test accuracy: 0.3840999901294708\n"
     ]
    }
   ],
   "source": [
    "# изменим Dropout\n",
    "\n",
    "# установка параметров нейросети\n",
    "batch_size = 32\n",
    "num_classes = 10\n",
    "epochs = 1\n",
    "data_augmentation = True\n",
    "num_predictions = 20\n",
    "save_dir = os.path.join(os.getcwd(), 'saved_models')\n",
    "model_name = 'keras_cifar10_trained_model_mod.h5'\n",
    "\n",
    "# разделение тренировочной и тестовой выборки\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "print('x_train shape:', x_train.shape)\n",
    "print(x_train.shape[0], 'тренировочные примеры')\n",
    "print(x_test.shape[0], 'тестовые примеры')\n",
    "\n",
    "# преобразование матрицы чисел 0-9 в бинарную матрицу чисел 0-1\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "\n",
    "# конфигурирование слоев нейросети\n",
    "model = Sequential()\n",
    "\n",
    "# слои нейросети отвественные за свертку и max-pooling\n",
    "model.add(Conv2D(32, (3, 3), padding='same',\n",
    "                 input_shape=x_train.shape[1:]))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(32, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3), padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(64, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "# полносвязные слои нейронной сети\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(num_classes))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "# инициализация RMSprop optimizer\n",
    "opt = keras.optimizers.RMSprop(lr=0.0001, decay=1e-6)\n",
    "\n",
    "# компиляция модели\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=opt,\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "\n",
    "if not data_augmentation:\n",
    "    print('Не используется data augmentation')\n",
    "    model.fit(x_train, y_train,\n",
    "              batch_size=batch_size,\n",
    "              epochs=epochs,\n",
    "              validation_data=(x_test, y_test),\n",
    "              shuffle=True)\n",
    "else:\n",
    "    print('Использование data augmentation в реальном времени')\n",
    "    # Препроцессинг и data augmentation в реальном времени:\n",
    "    datagen = ImageDataGenerator(\n",
    "        featurewise_center=False,\n",
    "        samplewise_center=False,\n",
    "        featurewise_std_normalization=False,\n",
    "        samplewise_std_normalization=False,\n",
    "        zca_whitening=False, \n",
    "        zca_epsilon=1e-06, \n",
    "        rotation_range=0, \n",
    "        width_shift_range=0.1,\n",
    "        height_shift_range=0.1,\n",
    "        shear_range=0., \n",
    "        zoom_range=0., \n",
    "        channel_shift_range=0.,\n",
    "        fill_mode='nearest',\n",
    "        cval=0.,\n",
    "        horizontal_flip=True,\n",
    "        vertical_flip=False,\n",
    "        rescale=None,\n",
    "        preprocessing_function=None,\n",
    "        data_format=None,\n",
    "        validation_split=0.0)\n",
    "\n",
    "    # запуск data augmentation через fit\n",
    "    #datagen.fit(x_train)\n",
    "\n",
    "    # запуск data augmentation через fit_generator\n",
    "    model.fit_generator(datagen.flow(x_train, y_train,\n",
    "                                     batch_size=batch_size),\n",
    "                        epochs=epochs,\n",
    "                        validation_data=(x_test, y_test),\n",
    "                        workers=4)\n",
    "\n",
    "# сохранение модели и весов\n",
    "if not os.path.isdir(save_dir):\n",
    "    os.makedirs(save_dir)\n",
    "model_path = os.path.join(save_dir, model_name)\n",
    "model.save(model_path)\n",
    "print('сохранить обученную модель как %s ' % model_path)\n",
    "\n",
    "# проверка работы обученной модели\n",
    "scores = model.evaluate(x_test, y_test, verbose=1)\n",
    "print('Test loss:', scores[0])\n",
    "print('Test accuracy:', scores[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (50000, 32, 32, 3)\n",
      "50000 тренировочные примеры\n",
      "10000 тестовые примеры\n",
      "Не используется data augmentation\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/5\n",
      "50000/50000 [==============================] - 93s 2ms/step - loss: 1.8163 - accuracy: 0.3302 - val_loss: 1.5953 - val_accuracy: 0.4237\n",
      "Epoch 2/5\n",
      "50000/50000 [==============================] - 382s 8ms/step - loss: 1.4936 - accuracy: 0.4601 - val_loss: 1.3266 - val_accuracy: 0.5254\n",
      "Epoch 3/5\n",
      "50000/50000 [==============================] - 96s 2ms/step - loss: 1.3480 - accuracy: 0.5179 - val_loss: 1.2130 - val_accuracy: 0.5698\n",
      "Epoch 4/5\n",
      "50000/50000 [==============================] - 972s 19ms/step - loss: 1.2552 - accuracy: 0.5520 - val_loss: 1.1966 - val_accuracy: 0.5747\n",
      "Epoch 5/5\n",
      "50000/50000 [==============================] - 395s 8ms/step - loss: 1.1769 - accuracy: 0.5823 - val_loss: 1.1004 - val_accuracy: 0.6125\n",
      "сохранить обученную модель как /Users/user/AnacondaProjects/introduction_to_neural_networks/lesson_04/saved_models/keras_cifar10_trained_model_mod.h5 \n",
      "10000/10000 [==============================] - 4s 375us/step\n",
      "Test loss: 1.1003936895370483\n",
      "Test accuracy: 0.612500011920929\n"
     ]
    }
   ],
   "source": [
    "# увеличим epochs\n",
    "# отключим data_augmentation\n",
    "\n",
    "# установка параметров нейросети\n",
    "batch_size = 32\n",
    "num_classes = 10\n",
    "epochs = 5\n",
    "data_augmentation = False\n",
    "num_predictions = 20\n",
    "save_dir = os.path.join(os.getcwd(), 'saved_models')\n",
    "model_name = 'keras_cifar10_trained_model_mod.h5'\n",
    "\n",
    "# разделение тренировочной и тестовой выборки\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "print('x_train shape:', x_train.shape)\n",
    "print(x_train.shape[0], 'тренировочные примеры')\n",
    "print(x_test.shape[0], 'тестовые примеры')\n",
    "\n",
    "# преобразование матрицы чисел 0-9 в бинарную матрицу чисел 0-1\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "\n",
    "# конфигурирование слоев нейросети\n",
    "model = Sequential()\n",
    "\n",
    "# слои нейросети отвественные за свертку и max-pooling\n",
    "model.add(Conv2D(32, (3, 3), padding='same',\n",
    "                 input_shape=x_train.shape[1:]))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(32, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3), padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(64, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "# полносвязные слои нейронной сети\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(num_classes))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "# инициализация RMSprop optimizer\n",
    "opt = keras.optimizers.RMSprop(lr=0.0001, decay=1e-6)\n",
    "\n",
    "# компиляция модели\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=opt,\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "\n",
    "if not data_augmentation:\n",
    "    print('Не используется data augmentation')\n",
    "    model.fit(x_train, y_train,\n",
    "              batch_size=batch_size,\n",
    "              epochs=epochs,\n",
    "              validation_data=(x_test, y_test),\n",
    "              shuffle=True)\n",
    "else:\n",
    "    print('Использование data augmentation в реальном времени')\n",
    "    # Препроцессинг и data augmentation в реальном времени:\n",
    "    datagen = ImageDataGenerator(\n",
    "        featurewise_center=False,\n",
    "        samplewise_center=False,\n",
    "        featurewise_std_normalization=False,\n",
    "        samplewise_std_normalization=False,\n",
    "        zca_whitening=False, \n",
    "        zca_epsilon=1e-06, \n",
    "        rotation_range=0, \n",
    "        width_shift_range=0.1,\n",
    "        height_shift_range=0.1,\n",
    "        shear_range=0., \n",
    "        zoom_range=0., \n",
    "        channel_shift_range=0.,\n",
    "        fill_mode='nearest',\n",
    "        cval=0.,\n",
    "        horizontal_flip=True,\n",
    "        vertical_flip=False,\n",
    "        rescale=None,\n",
    "        preprocessing_function=None,\n",
    "        data_format=None,\n",
    "        validation_split=0.0)\n",
    "\n",
    "    # запуск data augmentation через fit\n",
    "    #datagen.fit(x_train)\n",
    "\n",
    "    # запуск data augmentation через fit_generator\n",
    "    model.fit_generator(datagen.flow(x_train, y_train,\n",
    "                                     batch_size=batch_size),\n",
    "                        epochs=epochs,\n",
    "                        validation_data=(x_test, y_test),\n",
    "                        workers=4)\n",
    "\n",
    "# сохранение модели и весов\n",
    "if not os.path.isdir(save_dir):\n",
    "    os.makedirs(save_dir)\n",
    "model_path = os.path.join(save_dir, model_name)\n",
    "model.save(model_path)\n",
    "print('сохранить обученную модель как %s ' % model_path)\n",
    "\n",
    "# проверка работы обученной модели\n",
    "scores = model.evaluate(x_test, y_test, verbose=1)\n",
    "print('Test loss:', scores[0])\n",
    "print('Test accuracy:', scores[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# выводы\n",
    "\n",
    "# увеличение кол-ва эпох улучшает качество предсказаний нейронной сети\n",
    "# увеличение параметра batch_size приводит к ухудшению качества работы модели\n",
    "# отключение data_augmentation незначительно увеличивает качество нейросети\n",
    "# увеличение Dropout в сверточных слоях сети до 0.5 приводит к ухудшению качества\n",
    "\n",
    "# одновременное увеличение кол-ва эпох и отключение data_augmentation \n",
    "# позволило значительно улучшить качество работы нейронной сети"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CIFAR100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (50000, 32, 32, 3)\n",
      "50000 тренировочные примеры\n",
      "10000 тестовые примеры\n",
      "Использование data augmentation в реальном времени\n",
      "Epoch 1/1\n",
      "1563/1563 [==============================] - 105s 67ms/step - loss: 4.3308 - accuracy: 0.0409 - val_loss: 4.0219 - val_accuracy: 0.0984\n",
      "сохранить обученную модель как /Users/user/AnacondaProjects/introduction_to_neural_networks/lesson_04/saved_models/keras_cifar100_trained_model.h5 \n",
      "10000/10000 [==============================] - 4s 354us/step\n",
      "Test loss: 4.0218770126342775\n",
      "Test accuracy: 0.09839999675750732\n"
     ]
    }
   ],
   "source": [
    "# построим модель для cifar100, основанную на нейросети из урока\n",
    "\n",
    "from __future__ import print_function\n",
    "import keras # расскоментируйте эту строку, чтобы начать обучение\n",
    "from keras.datasets import cifar100\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "import os\n",
    "\n",
    "# установка параметров нейросети\n",
    "batch_size = 32\n",
    "num_classes = 100\n",
    "epochs = 1\n",
    "data_augmentation = True\n",
    "num_predictions = 20\n",
    "save_dir = os.path.join(os.getcwd(), 'saved_models')\n",
    "model_name = 'keras_cifar100_trained_model.h5'\n",
    "\n",
    "# разделение тренировочной и тестовой выборки\n",
    "(x_train, y_train), (x_test, y_test) = cifar100.load_data()\n",
    "print('x_train shape:', x_train.shape)\n",
    "print(x_train.shape[0], 'тренировочные примеры')\n",
    "print(x_test.shape[0], 'тестовые примеры')\n",
    "\n",
    "# преобразование матрицы чисел 0-99 в бинарную матрицу чисел 0-1\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "\n",
    "# конфигурирование слоев нейросети\n",
    "model = Sequential()\n",
    "\n",
    "# слои нейросети отвественные за свертку и max-pooling\n",
    "model.add(Conv2D(32, (3, 3), padding='same',\n",
    "                 input_shape=x_train.shape[1:]))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(32, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3), padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(64, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "# полносвязные слои нейронной сети\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(num_classes))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "# инициализация RMSprop optimizer\n",
    "opt = keras.optimizers.RMSprop(lr=0.0001, decay=1e-6)\n",
    "\n",
    "# компиляция модели\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=opt,\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "\n",
    "if not data_augmentation:\n",
    "    print('Не используется data augmentation')\n",
    "    model.fit(x_train, y_train,\n",
    "              batch_size=batch_size,\n",
    "              epochs=epochs,\n",
    "              validation_data=(x_test, y_test),\n",
    "              shuffle=True)\n",
    "else:\n",
    "    print('Использование data augmentation в реальном времени')\n",
    "    # Препроцессинг и data augmentation в реальном времени:\n",
    "    datagen = ImageDataGenerator(\n",
    "        featurewise_center=False,\n",
    "        samplewise_center=False,\n",
    "        featurewise_std_normalization=False,\n",
    "        samplewise_std_normalization=False,\n",
    "        zca_whitening=False, \n",
    "        zca_epsilon=1e-06, \n",
    "        rotation_range=0, \n",
    "        width_shift_range=0.1,\n",
    "        height_shift_range=0.1,\n",
    "        shear_range=0., \n",
    "        zoom_range=0., \n",
    "        channel_shift_range=0.,\n",
    "        fill_mode='nearest',\n",
    "        cval=0.,\n",
    "        horizontal_flip=True,\n",
    "        vertical_flip=False,\n",
    "        rescale=None,\n",
    "        preprocessing_function=None,\n",
    "        data_format=None,\n",
    "        validation_split=0.0)\n",
    "\n",
    "    # запуск data augmentation через fit\n",
    "    #datagen.fit(x_train)\n",
    "\n",
    "    # запуск data augmentation через fit_generator\n",
    "    model.fit_generator(datagen.flow(x_train, y_train,\n",
    "                                     batch_size=batch_size),\n",
    "                        epochs=epochs,\n",
    "                        validation_data=(x_test, y_test),\n",
    "                        workers=4)\n",
    "\n",
    "# сохранение модели и весов\n",
    "if not os.path.isdir(save_dir):\n",
    "    os.makedirs(save_dir)\n",
    "model_path = os.path.join(save_dir, model_name)\n",
    "model.save(model_path)\n",
    "print('сохранить обученную модель как %s ' % model_path)\n",
    "\n",
    "# проверка работы обученной модели\n",
    "scores = model.evaluate(x_test, y_test, verbose=1)\n",
    "print('Test loss:', scores[0])\n",
    "print('Test accuracy:', scores[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (50000, 32, 32, 3)\n",
      "50000 тренировочные примеры\n",
      "10000 тестовые примеры\n",
      "Не используется data augmentation\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/5\n",
      "50000/50000 [==============================] - 96s 2ms/step - loss: 4.3069 - accuracy: 0.0467 - val_loss: 3.9394 - val_accuracy: 0.1068\n",
      "Epoch 2/5\n",
      "50000/50000 [==============================] - 97s 2ms/step - loss: 3.8604 - accuracy: 0.1103 - val_loss: 3.6568 - val_accuracy: 0.1524\n",
      "Epoch 3/5\n",
      "50000/50000 [==============================] - 96s 2ms/step - loss: 3.6135 - accuracy: 0.1501 - val_loss: 3.3895 - val_accuracy: 0.2011\n",
      "Epoch 4/5\n",
      "50000/50000 [==============================] - 114s 2ms/step - loss: 3.4333 - accuracy: 0.1815 - val_loss: 3.2260 - val_accuracy: 0.2335\n",
      "Epoch 5/5\n",
      "50000/50000 [==============================] - 98s 2ms/step - loss: 3.2839 - accuracy: 0.2082 - val_loss: 3.0925 - val_accuracy: 0.2531\n",
      "сохранить обученную модель как /Users/user/AnacondaProjects/introduction_to_neural_networks/lesson_04/saved_models/keras_cifar100_trained_model_mod.h5 \n",
      "10000/10000 [==============================] - 3s 344us/step\n",
      "Test loss: 3.0924625442504885\n",
      "Test accuracy: 0.2531000077724457\n"
     ]
    }
   ],
   "source": [
    "# попробуем изменить кол-во эпох и отключить data_augmentation\n",
    "\n",
    "# установка параметров нейросети\n",
    "batch_size = 32\n",
    "num_classes = 100\n",
    "epochs = 5\n",
    "data_augmentation = False\n",
    "num_predictions = 20\n",
    "save_dir = os.path.join(os.getcwd(), 'saved_models')\n",
    "model_name = 'keras_cifar100_trained_model_mod.h5'\n",
    "\n",
    "# разделение тренировочной и тестовой выборки\n",
    "(x_train, y_train), (x_test, y_test) = cifar100.load_data()\n",
    "print('x_train shape:', x_train.shape)\n",
    "print(x_train.shape[0], 'тренировочные примеры')\n",
    "print(x_test.shape[0], 'тестовые примеры')\n",
    "\n",
    "# преобразование матрицы чисел 0-99 в бинарную матрицу чисел 0-1\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "\n",
    "# конфигурирование слоев нейросети\n",
    "model = Sequential()\n",
    "\n",
    "# слои нейросети отвественные за свертку и max-pooling\n",
    "model.add(Conv2D(32, (3, 3), padding='same',\n",
    "                 input_shape=x_train.shape[1:]))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(32, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3), padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(64, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "# полносвязные слои нейронной сети\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(num_classes))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "# инициализация RMSprop optimizer\n",
    "opt = keras.optimizers.RMSprop(lr=0.0001, decay=1e-6)\n",
    "\n",
    "# компиляция модели\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=opt,\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "\n",
    "if not data_augmentation:\n",
    "    print('Не используется data augmentation')\n",
    "    model.fit(x_train, y_train,\n",
    "              batch_size=batch_size,\n",
    "              epochs=epochs,\n",
    "              validation_data=(x_test, y_test),\n",
    "              shuffle=True)\n",
    "else:\n",
    "    print('Использование data augmentation в реальном времени')\n",
    "    # Препроцессинг и data augmentation в реальном времени:\n",
    "    datagen = ImageDataGenerator(\n",
    "        featurewise_center=False,\n",
    "        samplewise_center=False,\n",
    "        featurewise_std_normalization=False,\n",
    "        samplewise_std_normalization=False,\n",
    "        zca_whitening=False, \n",
    "        zca_epsilon=1e-06, \n",
    "        rotation_range=0, \n",
    "        width_shift_range=0.1,\n",
    "        height_shift_range=0.1,\n",
    "        shear_range=0., \n",
    "        zoom_range=0., \n",
    "        channel_shift_range=0.,\n",
    "        fill_mode='nearest',\n",
    "        cval=0.,\n",
    "        horizontal_flip=True,\n",
    "        vertical_flip=False,\n",
    "        rescale=None,\n",
    "        preprocessing_function=None,\n",
    "        data_format=None,\n",
    "        validation_split=0.0)\n",
    "\n",
    "    # запуск data augmentation через fit\n",
    "    #datagen.fit(x_train)\n",
    "\n",
    "    # запуск data augmentation через fit_generator\n",
    "    model.fit_generator(datagen.flow(x_train, y_train,\n",
    "                                     batch_size=batch_size),\n",
    "                        epochs=epochs,\n",
    "                        validation_data=(x_test, y_test),\n",
    "                        workers=4)\n",
    "\n",
    "# сохранение модели и весов\n",
    "if not os.path.isdir(save_dir):\n",
    "    os.makedirs(save_dir)\n",
    "model_path = os.path.join(save_dir, model_name)\n",
    "model.save(model_path)\n",
    "print('сохранить обученную модель как %s ' % model_path)\n",
    "\n",
    "# проверка работы обученной модели\n",
    "scores = model.evaluate(x_test, y_test, verbose=1)\n",
    "print('Test loss:', scores[0])\n",
    "print('Test accuracy:', scores[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# выводы\n",
    "\n",
    "# как и с cifar10, увеличение кол-ва эпох и отключение data_augmentation\n",
    "# привело к улучшению качества работы нейросети с cifar100"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
